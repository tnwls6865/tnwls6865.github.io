---
layout: post
title:  "End-to-End Object Detection with Transformers"
date:   2021-01-15 16:012:36 +0530
categories: paper
---



ì˜¤ëœë§Œì´ì§€ë§Œ..ì•ìœ¼ë¡œ ë” ê¾¸ì¤€íˆ ì½ê¸¸ ë°”ë¼ë©° ğŸ¤¡  

#### Abstract  

ê¸°ì¡´ì˜ object detectionë°©ë²•ì„ ì‚¬ì „ì§€ì‹ì„ ì´ìš©í•˜ëŠ” NMS(non-maximum suppression), anchorì™€ ê°™ì€ ê²ƒë“¤ì„ ì§€ì›€ìœ¼ë¡œì¨ ëª¨ë¸ êµ¬ì¡°ë¥¼ ê°„ì†Œí™”í•˜ì—¬ direct set prediction problemë¬¸ì œë¡œ ë°”ê¿”ì„œ í•´ê²°í•˜ë ¤í•¨  
ì œì•ˆí•˜ëŠ” frameworkì˜ ì´ë¦„ì€ DEtection TRansformer or DETRì´ë¼ê³  ë¶€ë¥´ê³  bipartite matchingê³¼ transformer encoder-decoderêµ¬ì¡°ë¥¼ í™œìš©í•˜ì—¬ set-based global loss ë¥¼ í™œìš©í•¨  
DETRì€ image contextì™€ objectì˜ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ê³  êµ¬ì¡°ê°€ ë§¤ìš° simpleí•¨ 

#### Introduction  

í˜„ëŒ€ detectorë“¤ì€ indirect ë°©ë²•ìœ¼ë¡œ detectionì„ ì§„í–‰í•¨  ë˜í•œ, object detectionì—ì„œëŠ” machine translation or speech recognitionê³¼ ê°™ì€ end-to-endë°©ì‹ì´ ì‚¬ìš©ë˜ì§€ ì•Šì•˜ì—ˆìŒ  
ê·¸ë˜ì„œ ë…¼ë¬¸ì—ì„œëŠ” direct set prediction problemìœ¼ë¡œ object detectionì˜ piplineì„ ê°„ì†Œí™”í•˜ì—¬ í•´ê²°í•˜ë ¤ê³  í•˜ë©°, transformer ê¸°ë°˜ì˜ encoder-decoderêµ¬ì¡°ë¥¼ í™œìš©í•¨  
![img1](/assets/post/post3/img1_.png)

Fig1ì€ DETRì„ êµ¬ì¡°ë¡œ ëª¨ë“  objectë¥¼ í•œë²ˆì— ì˜ˆì¸¡í•¨ ì´ë•Œ, predictedì™€ ground-truth objectê°„ì— bipartite matchingì„ í†µí•˜ì—¬ set loss functioní™œìš©í•˜ì—¬ end-to-endë¡œ í•™ìŠµí•  ìˆ˜ ìˆìŒ ê·¸ë¦¬ê³  customized layerê°€ í•„ìš”í•˜ì§€ ì•Šê³  ì–´ë–¤ frameworkë˜ì§€ ì‰½ê²Œ reproducedí•  ìˆ˜ ìˆìŒ  
Direct set predictionì‘ì—…ì„ í•˜ëŠ” ëª¨ë¸ê³¼ ë¹„êµí•˜ì˜€ì„ ë•Œ, main íŠ¹ì§•ì€ bipartite matching lossì™€ transformerë¥¼ ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ì ìœ¼ë¡œ decoding í•œë‹¤ëŠ” ê²ƒì„ ê¸°ì¡´ì˜ RNNì˜ ê²½ìš° Autoregressive decodingì— ì§‘ì¤‘í•˜ì˜€ì§€ë§Œ ë…¼ë¬¸ì˜ matching loss functionì€ ìœ ë‹ˆí¬í•˜ê²Œ GT objectë§ˆë‹¤ í•˜ë‚˜ì˜ predictionì— ë§¤ì¹­ë˜ê³  prediction objectì— ëŒ€í•´ì„œ permuitation invariantí•´ì„œ ë³‘ë ¬ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ  (permutation invariantë€ ì…ë ¥ ë²¡í„° ìš”ì†Œì˜ ìˆœì„œì™€ ìƒê´€ì—†ì´ ê°™ì€ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” ëª¨ë¸)

#### The DETR model

* prediction ê³¼ GT boxes ê°„ì˜ ìœ ë‹ˆí¬í•œ mathcingì„ ê°•í•˜ê²Œ í•˜ëŠ” a set prediction loss  

  1. Object detection set prediction loss  
     DETRì€ ê³ ì •ëœ Nê°œì˜ predictionì„ ì¶”ë¡ í•¨ (ë‚´ ìƒê°ì— Nì€ class..) í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì—ì„œ ì „í˜•ì ìœ¼ë¡œ ë¬¼ì²´ ê°¯ìˆ˜ë³´ë‹¤ ë” ë§ì€ ìˆ«ìë¡œ Nì„ ì‚¬ìš©í•¨  
     main difficultiesëŠ” GTì— ë§ì¶° prediction objects(class, position, size)ì™€ì˜ scoreë¥¼ í›ˆë ¨ì‹œí‚¤ëŠ” ê²ƒ  
     ê·¸ë˜ì„œ ì œì•ˆí•˜ëŠ” lossë¥¼ í†µí•´ì„œ predictedì™€ GT objectê°„ì˜ optimalí•œ bipartite matchingì„ ë§Œë“¤ì–´ëƒˆê³  ì´ëŠ” object-specific(bounding box) lossesë¥¼ ìµœì í™” í–ˆìŒ  
     ![loss1](/assets/post/post3/img2_.png)

     $y$ ëŠ” ground truth, $\hat{y} = {\hat{y_i}^{N}_{i=1}}$ ëŠ” Nê°œì˜ prediction set Nì€ ì´ë¯¸ì§€ ë‚´ì˜ ê°ì²´ ìˆ˜ ë³´ë‹¤ ë§ë‹¤ê³  ê°€ì •í•˜ë¯€ë¡œ $y$ì— N sizeì— ë§ê²Œ $\varnothing$ (no object)ë¡œ paddingì²˜ë¦¬ í•˜ë‚˜ì˜ ìš”ì†Œê°€ Nìš”ì†Œì— í¬í•¨ë˜ëŠ” ê²ƒì„ ì´ë¶„ ë§¤ì¹­ìœ¼ë¡œ ì°¾ì•˜ì„ ë•Œ  $\sigma$ëŠ” ê°€ì¥ ë‚®ìŒ  
     ì¦‰, transformerì˜ ë””ì½”ë”ê°€ ì˜ˆì¸¡í•˜ëŠ” ê°ì²´ì˜ classê°€ GT ê°ì²´ í¬í•¨ì´ ë  ë•Œ, lossê°€ ë‚®ì•„ì§  
     $\mathcal{L}_{match}(y_i, \hat{y_{\sigma(i)}})$ëŠ” GTì™€ predictionì— ëŒ€í•œ pair-wise matching cost optimal assignmentëŠ” Hungarian algorithmì„ í™œìš©í•¨
     (TODO, Hungarian algorithm ì„¤ëª… ì¶”ê°€ í•˜ê¸° )  
     <img src="/assets/post/post3/img3_.png" alt="loss2" style="zoom:67%;" />

     $\mathcal{L}_{match}(y_i, \hat{y_{\sigma(i)}})$ ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆìŒ GTì˜ ê° element $i$ ë¥¼ $y_i = (c_i, b_i)$ë¼ê³  í•  ë•Œ, $c_i$ëŠ” classê°€ ë˜ê³  $b_i$ëŠ” bboxê°€ ë¨ index $\sigma(i)$ì˜ predictionì— ëŒ€í•œ class $c_i$ì˜ probabilitysms $\hat{p}_{\sigma(i)}(c_i)$(ì´ë•Œ, ì•ì— -ë¥¼ ë¶™ì´ëŠ” ê²ƒì€ probabilityëŠ” í™•ë¥ ì´ê¸° ë•Œë¬¸ì— lossì— ì ìš©í•˜ê¸° ìœ„í•´ì„œ -ë¥¼ ë¶™ì¸ ê²ƒ ê°™ìŒ) ì´ê³  prediction bboxëŠ” $\hat{b}_{\sigma(i)}$ì„ ì´ëŸ¬í•œ ê³¼ì •ì€ one-to-oneì´ë¯€ë¡œ ì¤‘ë³µë˜ëŠ” predictionì´ ë‚˜ì˜¤ì§€ ì•Šê³  Hungarian lossë¥¼ í™œìš©í•˜ì—¬ ëª¨ë“  ìŒì„ ë§¤ì¹­  
     <img src="/assets/post/post3/img4_.png" alt="loss3"/>

     ì´í›„ cross entropy ì²˜ëŸ¼ logë¥¼ ì ìš©í•˜ì—¬ loss.  no objectì— ëŒ€í•´ì„œ ê°€ì¤‘ì¹˜ì— 10 ê°ì†Œë¥¼ ì¤Œ predctionì— ì˜í–¥ì´ ì—†ì–´ì„œ ë¹„ìš©ì´ ê°™ìŒ  
     Bounding box loss  
     ê¸°ì¡´ L1 lossëŠ” ê°™ì€ ì˜¤ë¥˜ë¼ë„ bbox ì‚¬ì´ì¦ˆì— ë”°ë¼ì„œ errorê°€ ë‹¤ë¦„ ê·¸ë˜ì„œ scaleì— ë¶ˆë³€í•˜ëŠ” IoU lossë¥¼ í™œìš©  
     <img src="/assets/post/post3/img5_.png" alt="loss4" style="zoom:67%;" />

* Architecture 
  ![img6](/assets/post/post3/img6.png)
  ì„¸ ê°€ì§€ main componentsë¡œ ì´ë£¨ì–´ì ¸ìˆìŒ  

  1. CNN backbone(ResNetì„ ì‚¬ìš©í•¨)  
     ê¸°ì¡´ì˜ CNN backboneëª¨ë¸ë¡œ lower-resolution activation map(32ë°°ë¡œ ì¤„ì„, C(ì±„ë„)ì€ 2048)ì„ ìƒì„±í•¨  
  2. encoder-decoder transformer  
     Encoder  
     1x1 convë¥¼ ì‚¬ìš©í•´ì„œ C(2048)ë¥¼ ì‘ì€ dimension dë¡œ ì¤„ì—¬ì¤Œ  
     transformer encoderëŠ” sequenceê°€ inputì´ê¸° ë•Œë¬¸ì— feature mapì„ dxH/32xW/32 -> dxH/32*W/32  
     encoder layerëŠ” ê¸°ì¡´ì˜ standardêµ¬ì¡°ì´ê³  multi-head, self attention module, feed forward netwrokë¡œ êµ¬ì„±ë˜ì–´ìˆìŒ  
     transformerëŠ” permutation-invariantì´ê¸° ë•Œë¬¸ì—, attention layerë¥¼ ì´ìš©í•´  fixed positional encodingì„ í™œìš©í•˜ì˜€ìŒ  
     Decoder  
     decoderëŠ” transformerì˜ í‘œì¤€ êµ¬ì¡°ë¥¼ ë”°ë¥´ê³ , multi-head, self encoder-decoder attention mechanismsìœ¼ë¡œ d dimensionì„ Nìœ¼ë¡œ embeddingí•¨  
     position embeedingê³¼ ë¹„ìŠ·í•œ attion layerë¥¼ ì‚¬ìš©í•´ì„œ object queryë¥¼ ì¶”ê°€í•¨  
     object queryì¸ Nê°œì˜ predictionìœ¼ë¡œ decoder outputì„ ì–»ìŒ  
     í•™ìŠµì—ì„œ ëª¨ë¸ outputeì˜ ë¬¼ì²´ì˜ ìˆ«ìê°€ ì •í™•í•  ìˆ˜ ìˆë„ë¡ Auxiliary decodinf lossë¡œ FFNê³¼ Hungarian lossë¥¼ ê° decoder layerí›„ì— ì¶”ê°€í•¨ 
  3. simple feed forward network(FFN)
     ë§ˆì§€ë§‰ predictionì€  3-layer perceptron with RELU, hidden dimension d , linear projection layerë¡œ ì–»ìŒ  
     outputì€ normalizedëœ center ì¢Œí‘œ, Height, width ê·¸ë¦¬ê³   softmaxë¥¼ ì‚¬ìš©í• ì—¬ linear layerê°€ ì˜ˆì¸¡í•œ class label  

#### Experiments

Faster R-CNNê³¼ì˜ ê²°ê³¼ ë¹„êµ  
![img7](/assets/post/post3/img7.png)

encoderì˜ í¬ê¸°ì— ë”°ë¥¸ ì˜í–¥ì„ ë‚˜íƒ€ë‚´ëŠ” ê²°ê³¼  
encoderì˜ layerê°€ ê¹Šì–´ì§ˆ ìˆ˜ë¡ APê°€ ì¦ê°€  
![img8](/assets/post/post3/img8.png)  

encoderì˜ self-attention visualization  
![img9](/assets/post/post3/img9.png)  

decoder layerì— ë”°ë¥¸ AP ê²°ê³¼  
![img10](/assets/post/post3/img10.png)

#### Conclusion

Object Detectionì—ì„œ transformerê¸°ë°˜ end-to-endë°©ì‹ì˜ ìƒˆë¡œìš´ êµ¬ì¡°ë¥¼ ì œì•ˆí•¨  
2 stageì¸ Faster R-CNNê³¼ ê²°ê³¼ê°€ ë¹„ìŠ·í•˜ë©°(large ë¬¼ì²´ì—ì„  ë” ì¢‹ì€ ê²°ê³¼) Panoptic segmentationìœ¼ë¡œ í™•ì¥ì´ ì‰¬ì›€  





-> Directë¡œ ë¬¼ì²´ë¥¼ matchingì‹œí‚¨ë‹¤ëŠ”ê²Œ ì¬ë°Œì—ˆê³ , ViTì´í›„ ë°”ë¡œ object detectionì— ì ìš©ì‹œì¼°ë‹¤ëŠ”ê²Œ í¥ë¯¸ë¡œì› ìŒ  
ViTë…¼ë¬¸ë„ ê³§ ì •ë¦¬ì˜ˆì •!


---
layout: post
title:  "End-to-End Object Detection with Transformers"
date:   2021-01-15 14:03:36 +0530
categories: paper
---

### End-to-End Object Detection with Transformers

ì˜¤ëœë§Œì´ì§€ë§Œ..ì•ìœ¼ë¡œ ë” ê¾¸ì¤€íˆ ì½ê¸¸ ë°”ë¼ë©° ğŸ¤¡  

#### Abstract  

ê¸°ì¡´ì˜ object detectionë°©ë²•ì„ ì‚¬ì „ì§€ì‹ì„ ì´ìš©í•˜ëŠ” NMS(non-maximum suppression), anchorì™€ ê°™ì€ ê²ƒë“¤ì„ ì§€ì›€ìœ¼ë¡œì¨ ëª¨ë¸ êµ¬ì¡°ë¥¼ ê°„ì†Œí™”í•˜ì—¬ direct set prediction problemë¬¸ì œë¡œ ë°”ê¿”ì„œ í•´ê²°í•˜ë ¤í•¨  
ì œì•ˆí•˜ëŠ” frameworkì˜ ì´ë¦„ì€ DEtection TRansformer or DETRì´ë¼ê³  ë¶€ë¥´ê³  bipartite matchingê³¼ transformer encoder-decoderêµ¬ì¡°ë¥¼ í™œìš©í•˜ì—¬ set-based global loss ë¥¼ í™œìš©í•¨  
DETRì€ image contextì™€ objectì˜ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ê³  êµ¬ì¡°ê°€ ë§¤ìš° simpleí•¨ 

#### Introduction  

í˜„ëŒ€ detectorë“¤ì€ indirect ë°©ë²•ìœ¼ë¡œ detectionì„ ì§„í–‰í•¨  ë˜í•œ, object detectionì—ì„œëŠ” machine translation or speech recognitionê³¼ ê°™ì€ end-to-endë°©ì‹ì´ ì‚¬ìš©ë˜ì§€ ì•Šì•˜ì—ˆìŒ  
ê·¸ë˜ì„œ ë…¼ë¬¸ì—ì„œëŠ” direct set prediction problemìœ¼ë¡œ object detectionì˜ piplineì„ ê°„ì†Œí™”í•˜ì—¬ í•´ê²°í•˜ë ¤ê³  í•˜ë©°, transformer ê¸°ë°˜ì˜ encoder-decoderêµ¬ì¡°ë¥¼ í™œìš©í•¨  
![image-20210115145557771](/assets/post/post3/img1.png)

Fig1ì€ DETRì„ êµ¬ì¡°ë¡œ ëª¨ë“  objectë¥¼ í•œë²ˆì— ì˜ˆì¸¡í•¨ ì´ë•Œ, predictedì™€ ground-truth objectê°„ì— bipartite matchingì„ í†µí•˜ì—¬ set loss functioní™œìš©í•˜ì—¬ end-to-endë¡œ í•™ìŠµí•  ìˆ˜ ìˆìŒ ê·¸ë¦¬ê³  customized layerê°€ í•„ìš”í•˜ì§€ ì•Šê³  ì–´ë–¤ frameworkë˜ì§€ ì‰½ê²Œ reproducedí•  ìˆ˜ ìˆìŒ  
Direct set predictionì‘ì—…ì„ í•˜ëŠ” ëª¨ë¸ê³¼ ë¹„êµí•˜ì˜€ì„ ë•Œ, main íŠ¹ì§•ì€ bipartite matching lossì™€ transformerë¥¼ ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ì ìœ¼ë¡œ decoding í•œë‹¤ëŠ” ê²ƒì„ ê¸°ì¡´ì˜ RNNì˜ ê²½ìš° Autoregressive decodingì— ì§‘ì¤‘í•˜ì˜€ì§€ë§Œ ë…¼ë¬¸ì˜ matching loss functionì€ ìœ ë‹ˆí¬í•˜ê²Œ GT objectë§ˆë‹¤ í•˜ë‚˜ì˜ predictionì— ë§¤ì¹­ë˜ê³  prediction objectì— ëŒ€í•´ì„œ permuitation invariantí•´ì„œ ë³‘ë ¬ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ  (permutation invariantë€ ì…ë ¥ ë²¡í„° ìš”ì†Œì˜ ìˆœì„œì™€ ìƒê´€ì—†ì´ ê°™ì€ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” ëª¨ë¸)

#### The DETR model

* prediction ê³¼ GT boxes ê°„ì˜ ìœ ë‹ˆí¬í•œ mathcingì„ ê°•í•˜ê²Œ í•˜ëŠ” a set prediction loss  

  1. Object detection set prediction loss  
     DETRì€ ê³ ì •ëœ Nê°œì˜ predictionì„ ì¶”ë¡ í•¨ (ë‚´ ìƒê°ì— Nì€ class..) í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì—ì„œ ì „í˜•ì ìœ¼ë¡œ ë¬¼ì²´ ê°¯ìˆ˜ë³´ë‹¤ ë” ë§ì€ ìˆ«ìë¡œ Nì„ ì‚¬ìš©í•¨  
     main difficultiesëŠ” GTì— ë§ì¶° prediction objects(class, position, size)ì™€ì˜ scoreë¥¼ í›ˆë ¨ì‹œí‚¤ëŠ” ê²ƒ  
     ê·¸ë˜ì„œ ì œì•ˆí•˜ëŠ” lossë¥¼ í†µí•´ì„œ predictedì™€ GT objectê°„ì˜ optimalí•œ bipartite matchingì„ ë§Œë“¤ì–´ëƒˆê³  ì´ëŠ” object-specific(bounding box) lossesë¥¼ ìµœì í™” í–ˆìŒ  
     ![image-20210115145557771](/assets/post/post3/img2.png)

     $y$ ëŠ” ground truth, $\hat{y} = {\hat{y_i}^{N}_{i=1}}$ ëŠ” Nê°œì˜ prediction set Nì€ ì´ë¯¸ì§€ ë‚´ì˜ ê°ì²´ ìˆ˜ ë³´ë‹¤ ë§ë‹¤ê³  ê°€ì •í•˜ë¯€ë¡œ $y$ì— N sizeì— ë§ê²Œ $\varnothing$ (no object)ë¡œ paddingì²˜ë¦¬ í•˜ë‚˜ì˜ ìš”ì†Œê°€ Nìš”ì†Œì— í¬í•¨ë˜ëŠ” ê²ƒì„ ì´ë¶„ ë§¤ì¹­ìœ¼ë¡œ ì°¾ì•˜ì„ ë•Œ  $\sigma$ëŠ” ê°€ì¥ ë‚®ìŒ  
     ì¦‰, transformerì˜ ë””ì½”ë”ê°€ ì˜ˆì¸¡í•˜ëŠ” ê°ì²´ì˜ classê°€ GT ê°ì²´ í¬í•¨ì´ ë  ë•Œ, lossê°€ ë‚®ì•„ì§  
     $\mathcal{L}_{match}(y_i, \hat{y_{\sigma(i)}})$ëŠ” GTì™€ predictionì— ëŒ€í•œ pair-wise matching cost optimal assignmentëŠ” Hungarian algorithmì„ í™œìš©í•¨
     (TODO, Hungarian algorithm ì„¤ëª… ì¶”ê°€ í•˜ê¸° )  
     <img src="/assets/post/post3/img3.png" alt="image-20210115145557771" style="zoom:67%;" />

     $\mathcal{L}_{match}(y_i, \hat{y_{\sigma(i)}})$ ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆìŒ GTì˜ ê° element $i$ ë¥¼ $y_i = (c_i, b_i)$ë¼ê³  í•  ë•Œ, $c_i$ëŠ” classê°€ ë˜ê³  $b_i$ëŠ” bboxê°€ ë¨ index $\sigma(i)$ì˜ predictionì— ëŒ€í•œ class $c_i$ì˜ probabilitysms $\hat{p}_{\sigma(i)}(c_i)$(ì´ë•Œ, ì•ì— -ë¥¼ ë¶™ì´ëŠ” ê²ƒì€ probabilityëŠ” í™•ë¥ ì´ê¸° ë•Œë¬¸ì— lossì— ì ìš©í•˜ê¸° ìœ„í•´ì„œ -ë¥¼ ë¶™ì¸ ê²ƒ ê°™ìŒ) ì´ê³  prediction bboxëŠ” $\hat{b}_{\sigma(i)}$ì„ ì´ëŸ¬í•œ ê³¼ì •ì€ one-to-oneì´ë¯€ë¡œ ì¤‘ë³µë˜ëŠ” predictionì´ ë‚˜ì˜¤ì§€ ì•Šê³  Hungarian lossë¥¼ í™œìš©í•˜ì—¬ ëª¨ë“  ìŒì„ ë§¤ì¹­  
     <img src="/assets/post/post3/img4.png" alt="image-20210115145557771"/>

     ì´í›„ cross entropy ì²˜ëŸ¼ logë¥¼ ì ìš©í•˜ì—¬ loss.  no objectì— ëŒ€í•´ì„œ ê°€ì¤‘ì¹˜ì— 10 ê°ì†Œë¥¼ ì¤Œ predctionì— ì˜í–¥ì´ ì—†ì–´ì„œ ë¹„ìš©ì´ ê°™ìŒ  
     Bounding box loss  
     ê¸°ì¡´ L1 lossëŠ” ê°™ì€ ì˜¤ë¥˜ë¼ë„ bbox ì‚¬ì´ì¦ˆì— ë”°ë¼ì„œ errorê°€ ë‹¤ë¦„ ê·¸ë˜ì„œ scaleì— ë¶ˆë³€í•˜ëŠ” IoU lossë¥¼ í™œìš©  
     <img src="/assets/post/post3/img5.png" alt="image-20210115145557771" style="zoom:67%;" />

* Architecture 


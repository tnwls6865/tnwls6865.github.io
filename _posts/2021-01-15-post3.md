---
layout: post
title:  "End-to-End Object Detection with Transformers"
date:   2021-01-15 14:03:36 +0530
categories: paper
---

### End-to-End Object Detection with Transformers

오랜만이지만..앞으로 더 꾸준히 읽길 바라며 🤡  

#### Abstract  

기존의 object detection방법을 사전지식을 이용하는 NMS(non-maximum suppression), anchor와 같은 것들을 지움으로써 모델 구조를 간소화하여 direct set prediction problem문제로 바꿔서 해결하려함  
제안하는 framework의 이름은 DEtection TRansformer or DETR이라고 부르고 bipartite matching과 transformer encoder-decoder구조를 활용하여 set-based global loss 를 활용함  
DETR은 image context와 object의 관계를 추출하고 구조가 매우 simple함 

#### Introduction  

현대 detector들은 indirect 방법으로 detection을 진행함  또한, object detection에서는 machine translation or speech recognition과 같은 end-to-end방식이 사용되지 않았었음  
그래서 논문에서는 direct set prediction problem으로 object detection의 pipline을 간소화하여 해결하려고 하며, transformer 기반의 encoder-decoder구조를 활용함  
![image-20210115145557771](/assets/post/post3/img1.png)

Fig1은 DETR을 구조로 모든 object를 한번에 예측함 이때, predicted와 ground-truth object간에 bipartite matching을 통하여 set loss function활용하여 end-to-end로 학습할 수 있음 그리고 customized layer가 필요하지 않고 어떤 framework던지 쉽게 reproduced할 수 있음  
Direct set prediction작업을 하는 모델과 비교하였을 때, main 특징은 bipartite matching loss와 transformer를 사용하여 병렬적으로 decoding 한다는 것임 기존의 RNN의 경우 Autoregressive decoding에 집중하였지만 논문의 matching loss function은 유니크하게 GT object마다 하나의 prediction에 매칭되고 prediction object에 대해서 permuitation invariant해서 병렬적으로 사용할 수 있음  (permutation invariant란 입력 벡터 요소의 순서와 상관없이 같은 출력을 생성하는 모델)

#### The DETR model

* prediction 과 GT boxes 간의 유니크한 mathcing을 강하게 하는 a set prediction loss  

  1. Object detection set prediction loss  
     DETR은 고정된 N개의 prediction을 추론함 (내 생각에 N은 class..) 하나의 이미지에서 전형적으로 물체 갯수보다 더 많은 숫자로 N을 사용함  
     main difficulties는 GT에 맞춰 prediction objects(class, position, size)와의 score를 훈련시키는 것  
     그래서 제안하는 loss를 통해서 predicted와 GT object간의 optimal한 bipartite matching을 만들어냈고 이는 object-specific(bounding box) losses를 최적화 했음  
     ![image-20210115145557771](/assets/post/post3/img2.png)

     $y$ 는 ground truth, $\hat{y} = {\hat{y_i}^{N}_{i=1}}$ 는 N개의 prediction set N은 이미지 내의 객체 수 보다 많다고 가정하므로 $y$에 N size에 맞게 $\varnothing$ (no object)로 padding처리 하나의 요소가 N요소에 포함되는 것을 이분 매칭으로 찾았을 때  $\sigma$는 가장 낮음  
     즉, transformer의 디코더가 예측하는 객체의 class가 GT 객체 포함이 될 때, loss가 낮아짐  
     $\mathcal{L}_{match}(y_i, \hat{y_{\sigma(i)}})$는 GT와 prediction에 대한 pair-wise matching cost optimal assignment는 Hungarian algorithm을 활용함
     (TODO, Hungarian algorithm 설명 추가 하기 )  
     <img src="/assets/post/post3/img3.png" alt="image-20210115145557771" style="zoom:67%;" />

     $\mathcal{L}_{match}(y_i, \hat{y_{\sigma(i)}})$ 를 다음과 같이 표현할 수 있음 GT의 각 element $i$ 를 $y_i = (c_i, b_i)$라고 할 때, $c_i$는 class가 되고 $b_i$는 bbox가 됨 index $\sigma(i)$의 prediction에 대한 class $c_i$의 probabilitysms $\hat{p}_{\sigma(i)}(c_i)$(이때, 앞에 -를 붙이는 것은 probability는 확률이기 때문에 loss에 적용하기 위해서 -를 붙인 것 같음) 이고 prediction bbox는 $\hat{b}_{\sigma(i)}$임 이러한 과정은 one-to-one이므로 중복되는 prediction이 나오지 않고 Hungarian loss를 활용하여 모든 쌍을 매칭  
     <img src="/assets/post/post3/img4.png" alt="image-20210115145557771"/>

     이후 cross entropy 처럼 log를 적용하여 loss.  no object에 대해서 가중치에 10 감소를 줌 predction에 영향이 없어서 비용이 같음  
     Bounding box loss  
     기존 L1 loss는 같은 오류라도 bbox 사이즈에 따라서 error가 다름 그래서 scale에 불변하는 IoU loss를 활용  
     <img src="/assets/post/post3/img5.png" alt="image-20210115145557771" style="zoom:67%;" />

* Architecture 


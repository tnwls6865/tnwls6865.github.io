---
layout: post
title:  "Where to Look?: Mining Complementary Image Regions for Weakly Supervised Object Localization ì •ë¦¬"
date:   2021-04-23 15:42:36 +0530
categories: paper
---



ê°„ë§Œì— ì½ê³  ë°”ë¡œ ì •ë¦¬ğŸ™‚ğŸ™‚

### Abstract

ì‚¬ëŒì€ ì‚¬ë¬¼ê³¼ ê·¸ì— ìƒì‘ í•˜ëŠ” ë¶€ë¶„ì„ ì¸ì‹í•˜ëŠ” íƒ€ê³ ë‚œ ëŠ¥ë ¥ì„ ê°€ì§€ê³  ìˆìœ¼ë©° ì‚¬ë¬¼ì´ ê³µê°„ì ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” ì‹œê°ì  ì¥ë©´ì—ì„œ ê·¸ ìœ„ì¹˜ì— ì£¼ì˜ë¥¼ ì§‘ì¤‘ì‹œí‚´ ìµœê·¼ì— image-levelì˜ labelì„ ì‚¬ìš©í•´ì„œ localizationí•˜ëŠ” weakly supervied object localization ì—°êµ¬ë“¤ì´ ì§„í–‰ë˜ì–´ì§€ê³  ìˆìŒ. ì´ë•Œ ì˜ ì•Œë ¤ì§„ ë°©ë²• ì¤‘ í•˜ë‚˜ì˜ ë¬¸ì œëŠ” ë¬¼ì²´ì˜ discriminativeí•œ ë¶€ë¶„ì„ localizingí•œë‹¤ëŠ” ê²ƒì„ ê·¸ë˜ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ë¯¸ì§€ ë‚´ì˜ complementary regionìœ¼ë¡œë¶€í„° mining í•¨ìœ¼ë¡œì¨ ì´ë¯¸ì§€ ì „ì²´ì— ëŒ€í•´ì„œ ë©´ë°€í•˜ê²Œ localizingí•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì œì•ˆí•¨ regional dropoutë°©ë²•ì„ ì‚¬ìš©í•´ì„œ complemetrayì´ë¯¸ì§€ë¥¼ ìƒì„±í•¨ ê·¸ë¦¬ê³  Channel-wise Assited Attention Module, Spatial Self-Attention Moudle ë°©ë²•ì„ ì‚¬ìš©í•¨ ë§ˆì§€ë§‰ìœ¼ë¡œ Attention-based Fusion Lossë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ê°œì˜ classifierì—ì„œ attention mapì„ ì‚¬ìš©í•¨ ì´ë ‡ê²Œ í•´ì„œ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ê±°ë‘˜ ìˆ˜ ìˆì—ˆìŒ 

### Introduction

ê¸°ì¡´ì˜ CAMì„ ë§ì´ ì‚¬ìš©í–ˆëŠ”ë°, CAMì€ object categoryë¥¼ ì¸ì‹í•˜ê¸° ìœ„í•´ì„œ image regionì—ì„œ discriminativeí•œ ë¶€ë¶„ì„ highlightí•¨ í•˜ì§€ë§Œ ì´ë ‡ê²Œ ë˜ë©´ ì „ì²´ objectê°€ ì•„ë‹Œ class-specific regionì— ëŒ€í•´ì„œë§Œ localizationì´ ë¨ ê·¸ë˜ì„œ CAMì„ ì´ìš©í•˜ëŠ”ê²ƒì€ sub-optimalí•¨ 

ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ì„œ Hide-and-Seek(HaS)ëŠ” í•™ìŠµë™ì•ˆ ì´ë¯¸ì§€ì—ì„œ ëœë¤ìœ¼ë¡œ hide patchë¥¼ ì‹œë„í•˜ì˜€ìŒ ëª¨ë¸ì´ objectì˜ visible relevant partë¥¼ ì°¾ê²Œ í•˜ê¸° ìœ„í•´ì„œ í•˜ì§€ë§Œ hide patchë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì •ë³´ ì†ì‹¤ì´ ì˜¤ê³  ì´ëŠ” localization ì„±ëŠ¥ì´ ë‚®ì•„ì§ ê·¸ë˜ì†Œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” "Is there any way to optimize the localization performance by maximally utilizing the information lost in regional dropout?"ì´ë¼ëŠ” ì˜ë¬¸ì„ ê°–ê²Œë¨

ê·¸ë˜ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” complementray inmage regionìœ¼ë¡œë¶€í„° informationì„ miningí•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•¨ Rgional dropoutì€ ëª¨ë¸ì˜ generalizaeë¿ë§Œ ì•„ë‹ˆë¼ image classification, object localizationì„±ëŠ¥ì„ ì˜¬ë ¤ì¤Œ ê·¸ë˜ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë‘ê°œì˜ complementary imageë¥¼ ìƒì„±í•˜ëŠ”ë°  regional dropoutì„ ì§„í–‰í•˜ëŠ”ë° ë‘ê°œì˜ ì´ë¯¸ì§€ê°€ ìƒí˜¸ë³´ì™„ì ì„   
![img1](/assets/post/post16/img1.png)

we perform joint training of these complementary image regions as two input channles, using parallel classifiers  ê·¸ë¦¬ê³  ë‘ ê°œì˜ input channel ì—ì„œ ì •ë³´ë¥¼ í¬ì°©í•˜ê¸° ìœ„í•´ì„œ CAAMê³¼ SSAMì„ ì‚¬ìš©í•¨    
CAAMì€ ë‘ ì´ë¯¸ì§€ì˜ feature ê°„ì˜ ì±„ë„ë¼ë¦¬ interation, SAAMì€ feature dependencyë¥¼ í¬ì°©í•˜ê¸° ìœ„í•´ì„œ    
ê·¸ë¦¬ê³  Attention mapì„ ìƒì„±í•˜ê³  ì‚¬ìš©í•˜ëŠ” Attention-based Fusion Lossë¥¼ ì œì•ˆí•¨ ì´ë ‡ê²Œ ì œì•ˆí•˜ëŠ” frameworkëŠ” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤Œ

### Related Work

Corerespondence with human visual perception   
ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì‚¬ëŒì˜ vision ì‹œìŠ¤í…œì—ì„œ ë™ê¸°ë¥¼ ë¶€ì—¬ë°›ì•„ what, whereê²½ë¡œë¥¼ ê³µë™ìœ¼ë¡œ ëª¨ë¸ë§í•˜ê³  weakly supervision í™˜ê²½ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ë¬¼ì²´ ìœ„ì¹˜ë¥¼ íŒŒì•…í•˜ë ¤ê³  í•¨   
Weakly Supervised Learning   
bounding boxë¥¼ ì´ìš©í•˜ëŠ” ê±°ëŠ” ì•½ê°„ì˜ ë¹„ìš©ì´ í•„ìš”í•˜ë¯€ë¡œ img-levelì˜ label ì„ ì´ìš©í•´ì„œ í•˜ëŠ”ê²ƒì´ ë” ì €ë ´í•¨   
Regional Dropout  
ì´ë¯¸ì§€ë‚´ì— íŠ¹ì • ì˜ì—­ì„ ëœë¤í•˜ê²Œ ë§ˆìŠ¤í‚¹í•˜ëŠ” ê²ƒì€ object contextë¥¼ í¬ì°©í•˜ëŠ”ë° íš¨ê³¼ì ì´ê³  ë” ë‚˜ì€ generalizationì„±ëŠ¥ì„ ì´ë” Hide-and-Seekì€ ê°€ì¥ ì¤‘ìš”í•œ ì ì„ patchë¡œ hideí•¨ìœ¼ë¡œì¨ ëª¨ë¸ì´ ë‹¤ë¥¸ relevant objectì— ì§‘ì¤‘ì„ í•  ìˆ˜ ìˆìŒ í•˜ì§€ë§Œ ê¸°ì¡´ ë°©ë²•ë“¤ì€ information loseê°€ ìˆê¸° ë•Œë¬¸ì— ë³¸ ë…¼ë¬¸ì—ì„œëŠ” comprementary spatial locationì„ í™œìš© 

### Method

![img2](/assets/post/post16/img2.png)

Mining Information from Complementary Image Regions  
ì´ë¯¸ì§€ê°€ ë“¤ì–´ì™”ì„ ë•Œ hide patch(ëœë¤)ì„ ì‚¬ìš©í•´ì„œ complementary imageë¥¼ ìƒì„±í•¨ ê·¸ë¦¬ê³  SSAMê³¼ CAAM ëª¨ë“ˆì„ ê°ê° ì‚¬ìš©í•´ì„œ fusedí•¨  ì´í›„ê°ì featureë¥¼ aggregateí•¨ ì´ë ‡ê²Œ ìƒì„±ëœ F^t_x, F^t_x2ëŠ” classifierì™€ global average poolingìœ¼ë¡œ passë¨

Channel-wise Assited Attention Module   
CAMì„ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œ feature mapì— weightë¥¼ multiplyí•¨ CNNì˜ last layerëŠ” class-specificí•œ ì‘ë‹µì„ í•˜ê¸° ë•Œë¬¸ì— CAMì€ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•´ objectì˜ most discriminative regionì„ highlightí•¨ ê·¸ë˜ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” F_x, F_x2ë¡œë¶€í„° input feautreì˜ channelê°„ì— classë³„ inter-dependenciesë¥¼ í™œìš©í•˜ê³ ì í•˜ì˜€ìŒ  input featureì˜ ì°¨ì›ì„ N=HWë¡œ í•´ì„œ CxNìœ¼ë¡œ ë³€ê²½í•¨ ì´í›„ channel attention matrix Q_xë¥¼ ë§Œë“¬ 

![img3](/assets/post/post16/img3.png)
![img4](/assets/post/post16/img4.png)

Q_xëŠ” attention weightì´ê³ , F_xì™€ F_x2ì˜ channelê°„ì˜ inter-dependecyë¥¼ í¬ì°©í•¨ ê·¸ë¦¬ê³  Q_xì™€ F_x2ë¥¼ ê³±í•´ì„œ Y_xë¥¼ ìƒì„± Y_xë¥¼ ë‹¤ì‹œ CxHxWë¡œ reshapeí•¨ F^c_x = F_x + scale factor*Y_xë¥¼ í•¨ 


### Experiments

---
layout: post
title:  "An image is worth 16x16 words transformers for image recognition at scale"
date:   2021-01-25 16:012:36 +0530
categories: paper
---





NLP에서 핫하던 Transformer를 Vision 분야에 처음 적용하면서 엄청 🔥했던 논문



**Introduction**

![img1](\assets\post\post5\img1.png)

Attention is all you need 논문에서 transformer가 소개되면서 NLP분야의 다양한 task에 대해서 활용이 되어졌음  
대형 Transformer기반 모델은 대형 corpus에 pre-trained한 후 GPT 및 BERT와 같은 다양한 task에 맞게 fine-tuning하고 이것은 NLP의 trend가 되었음  
Computer vision 분야에서 transforemr를 적용하려는 시도는 있었지만 효율적이지 않았고 대규모 이미지 인식에서 고전적인 ResNet이 base가 되는 모델들이 state of the art였음  
![img2](\assets\post\post5\img2.png)  
논문의 저자는 NLP 에서의 transformer확장의 성공에서 영감을 받아 가능한 최소한의 수정으로 이미지에 직접적으로 standard transformer를 적용하는 실험을 함  
그래서 supervision fashion으로 transformer를 활용하여 image classification에 적용함  

**Method**

![img3](\assets\post\post5\img3.png)  

image transfer는 NLP용으로 설계된 transformer구조를 따름 
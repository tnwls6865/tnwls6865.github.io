---
layout: post
title:  "Semi-Supervised Semantic Segmentation with Cross Pseudo Supervision 정리"
date:   2021-10-12 10:32:36 +0530
categories: paper
---



6개월만에 나타난 ㅎ_ㅎ..
요즘 관심 있는 semi-supervised learning paper

### Introduction

Consistency regularization은 semi-supervised semantic segmentation에 주로 활용되어짐 다양한 perturbation(input, feature, network)을 줘서 prediction의 constitency를 강화하게 하는 방법   
본 논문에서는 consistency regularization approach with network perturbation을 제안함 labeled and unlabeled images를 구조는 같지만 initialization이 다른 network에 feed함 labeled data의 output은 ground truth랑 supervised learning을 함 **본 논문의 point는 cross pseudo supervision을 통해 two segmentation network간의 consistency를 강화하는 cross pseudo supervision**    

- 제안하는 방법은 같은image에 대해 다르게 initializaion된 network의 prediction이 consistent되고 이는 prediction decision boundary가 low-density region에 놓이게 됨 
- pseudo segmentation은 optimization stage에서 stable and more accurate 

### Related Work

1. Semantic segmentation   
   대부분 FCN(Fully convolutional network)를 주로 사용: resolution, context, edge   
   본 논문에서는 unlabeled data를 어떻게 사용할지에 대해 focus 실험은 주로 DeepLabv3+, HRNet에 대해 진행
2. Semi-supervised semantic segmentation   
   수동으로 pixel level annotation을 하는건 very time-consuming and costly   
   Consistency regularization 다양한 perturbation의 predictions/intermediate의 consistency를 강화하는 것:
   Input, feature, network   
   Input perturbation method(augmentation:cutmix)는  augmented image의 prediction간의 consistency를 통제하고 이렇게 함으로써 decision function이 low-density region에 놓여짐    
   feature perturbation은 multiple decoder를 사용하여 feature pertubation을 줌 그리고 decoder의 output간의 consistency를 강화하는 것   
   network perturbation 은 same structure이지만 다르게 initialization된 segmentation network를 사용하고 perturbed network의 prediction간의  consistency를 강화함 
   **본 논문의 방법은 network perturbation과 비슷하지만 consistency를 주는 것은 pseudo segmentation map임**   
   GAN방법은 하나의 이미지에 대해 다양한 pertubation을 사용하여 consistency를 강화함 unlabeld data의 predicted segmentation map과 labeled data에 대한 gt segmentation map의 statistical feature 간의 consistency를 강화함 discriminator가 predicted segmentation 인지 gt segmentation map인지를 구별하는 것을 학습    
   Self-training(self-learning, self-labeling or decision directed learning)은 classification에서 unlabeld data에 대해 초기에 많이 활용되어짐 labeled data로 학습되어진 segmentation model을 통해 unlabeled data에 대해 pseudo segmentation map을 얻고 retraining 함   
   PseudoSeg는 pseudo segmentation을 사용하는 것이 본 논문과 비슷하지만 PseudoSeg는 FixMatch랑 비슷하게 single segmentation network에서 supervise에 대해 strongly augmentation, unsupervise에 대해 weakly augmentation하고 single network를 사용함 
3. Semi-supervised classification   
   semi-supervised classification에는 가정이 존재: smoothness, consistency, low-density or clustered    
   직관적으로 neighboring data는 높은 확률로 같은 class에 속하거나 low-density region에 decision boundary가 놓여있음    

### Method

* Cross pseudo supervision   
  two  parallel segmentation networks:   
  ![img1](/assets/post/post17/img1.png)   
  같은 구조지만 initilization이 다름 input X는 같은 augmentation을 적용함 P1, P2는 segmentation confidence map(softmax 이후의 network output )   
  ![img2](/assets/post/post17/img2.png)     
  Y1, Y2는 predicted one-hot label map => pseudo segmentation map      
  ![img3](/assets/post/post17/img3.png)     
   The complete version of our method is illustration

   The training objective contains two losses : supervision Loss L_s and corss pseudo supervision Loss L_cps    
  L_s는 standard pixel-wise cross-entropy loss on labeled images over the two parallel segmentation networks   
  ![img4](/assets/post/post17/img4.png)     
  *는 ground truth   
  L_cps는 bidirectional 하나는 f($$ \theta_1$$) 에서 $$f(\theta_2)$$로 감 pixel-wise confidence map P2를 supervise하기 위해 $$Y_1$$ 을 사용하고 다른 하나는 $$f(\theta_2)$$에서 $$f(\theta_1)$$로 감   
  ![img5](/assets/post/post17/img5.png)    
  labeled data에 대해서도 똑가은 방법으로 L_cps를 사용함  그래서 전체 cross pseudo supervision loss는 다음과 같음   
  $$L_{cps} = L^l_{cps} + L^u_{cps}$$    
  전체 로스는 $$L = L_s + \lambda L_{cps} $$ $$\lambda$$는 trade-off weight 

* Incorporation with the CutMix augmentation  
  두 개의 network $$f(\theta_1)$$와 $$f(\theta_2)$$에input으로 CutMixed image를 사용 input two source images (that are used to generate the CutMix images) into each segmentation network and mix the two pseudo segmentation maps as the supervision of the other segmentation network.

### Discussions

* Cross probability consistency   
  ![img6](/assets/post/post17/img6.png)    
  An optional consistency across the two perturbed networks is cross probability consistency: the probability vectors should be similar   
  ![img7](/assets/post/post17/img7.png)   
  loss는 L2 or KL-divergence 
* Mean teacher  
  ![img8](/assets/post/post17/img8.png)   
  다른 augmentation을 적용한 unlabeled image을 같은 구조의 network에 feed: 하나는 student $$f(\theta)$$ 다른 하나는 mean teacher $$f(\bar\theta)$$ $$\bar\theta$$는 student network의 moving average   
  ![img9](/assets/post/post17/img9.png)    
  X1, X2는 다른 augmentation consistency regularization은 student network에 의해 예측된 X1의 P1과 teacher network의 X2의 P2를 align하는 것을 목표로함 training동안 teacher network에 대해 back propagation하지 않고 P1에 대해 P2를 supervise함 
* Single-network pseudo supervision   
  ![img10](/assets/post/post17/img10.png)   
  same network, one weak augmentation and one strong augmentation  
  Y에서 P로 supervision loss  
  single-network pseudo supervision 은 성능이 잘 안나옴 이유는 동일한 네트워크의 pseudo label에 의한 supervision이 네트워크 자체를 학습하여 psudo label을 더 잘 approximate해서 잘못된 방향으로 수렴할 수 있음 반대로 network perturbation는 잘못된 방향으로 부터 어느정도 확률로 네트워크를 학습할 수 있음 즉, 두 네트워크 같의  pseudo label의 perturbation은 regularizer, 잘못된 방향에 대한 over-fitting free를 의미함   
  추가적으로 single-network pseudo supervision with CutMix augmentation을 실험함 two source image into a network $$f(\theta)$$ and 두개의 pseudo segmentation map을 섞음 이는 같은 network로 부터 cutmixed image의 output을 supervise하는데 사용함 
* PseudoSeg     
  ![img10](/assets/post/post17/img10.png)     
  PseudoSeg는 FixMatch 랑 비슷 X_w는 weakly augmentation image  X_s는 strong augmentation image  PseudoSeg는 Strongly-augmentation image X_s에 대해 back propagation을 진행  
  ![img11](/assets/post/post17/img11.png)      
  pseudo segmentation map from weak augmentation이 추가적인 perturbation이 있기때문에 좀 더 정확할 거라고 본 논문에서 추측함

### Experiments

Setup 

- Datasets   
  PASCAL VOC2012: 20 object, 1 background  / Cityscapes : 19 semantic label   
  Guided Collaborative Training방법을 follow random sampling을 통해 1/2, 1/4, 1/8/ 1/16으로 나눠서 labeled set, 나머지를 unlabeled set으로 나눔 
- Evaluation   
  mean IoU with only single scale testing 
- Implementation details   
  Pytorch framework   
  the weights pre-trained on ImageNet and the weights of two segmentation heads (of DeepLabv3+) randomly  
  mini-batch SGD with momentum 0.9/ weight decay 0.0005 / poly learning rate policy   
  random horizontal flipping / multi-scale  
  PASCAL VOC2012: 60 epochs with lr 0.01   
  Cityscapes: 240 epochs with lr 0.04, OHEM loss 

Results

* Improtvements over baselines   
  ![img12](/assets/post/post17/img12.png)   
  (a) Deeplabv3+ with ResNet-50 (b) Deeplabv3+ with ResNet-101   
* Comparison with SOTA  
  Mean-Teacher, Cross-Consistency Training, Guided Collaborative Training , CutMix-Seg  
  ![img13](/assets/post/post17/img13.png)  
  PASCAL VOC2012 results CutMix


---
layout: post
title:  "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"
date:   2021-03-16 20:34:36 +0530
categories: paper  
---



ì—°êµ¬ë¥¼ í•´ì•¼í•˜ëŠ”ë° ë¨¸ë¦¬ê°€ ì•ˆëŒì•„ê°„ë‹¤ ğŸ¤•ğŸ¤•

ê¸°ì¡´ì˜ FCN ê¸°ë°˜ì˜ encoder-decoderêµ¬ì¡°ê°€ ì•„ë‹Œ sequence-to-sequce í˜•íƒœë¡œ transformerë¥¼ segmentationì— ì ìš©í•œ ë…¼ë¬¸

**Introduction**

encoder-decoder : encoderëŠ” feature representation ê¸°ë°˜, decoderëŠ” pixel-level classificationì„ í•¨ ê·¸ë¦¬ê³  ì´ëŸ¬í•œ designì´ ì¸ê¸°ê°€ ìˆëŠ”ì´ìœ ëŠ” translation equivariance and localityë•Œë¬¸ì„ í•˜ì§€ë§Œ segmentationì—ì„œ ì¤‘ìš”í•œ long range dependency informationì„ í•™ìŠµí•˜ëŠ” ê²ƒì€ ì—¬ì „íˆ limited receptive fieldsë¡œ ì–´ë ¤ì›Œì§„ë‹¤ëŠ” í•œê³„ê°€ ìˆìŒ 

ê·¸ë˜ì„œ ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ ì ë‹¤ì–‘í•œ ë°©ë²•ë“¤ì´ ì—°êµ¬ë¨   
conv operationì„ ì¡°ì‘í•˜ëŠ” large kernel sizeì™€ atrous conv, image/feature pyramidë“±ê³¼ ê°™ì€ ë°©ë²•ë“¤ì´ ì—°êµ¬ë˜ì—ˆê³  attention module into FCN architectureë„ ìˆìŒ FCN moduleì€ ë°”ê¾¸ì§€ ì•Šì€ì±„ attentionê³¼ ê²°í•©í•˜ëŠ” ë°©ë²•ì„ í•˜ì§€ë§Œ ì´ë˜í•œ encoder-decoder êµ¬ì¡° encoderì—ì„œëŠ” input resolutionì„ ì¤„ì´ê³  decoderì—ì„œëŠ” lower-resolution feature ë¥¼ ê°œì„ í•˜ëŠ” ë°©ë²•ì„ 

ê·¸ë˜ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” encoder-decoderêµ¬ì¡°ê°€ ì•„ë‹Œ pure transformerêµ¬ì¡°ë¥¼ ì ìš©í•œ SETR(SEgmentation TRansformer)ë¥¼ ì œì•ˆí•¨ 
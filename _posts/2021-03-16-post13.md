---
layout: post
title:  "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"
date:   2021-03-16 20:34:36 +0530
categories: paper  
---



ì—°êµ¬ë¥¼ í•´ì•¼í•˜ëŠ”ë° ë¨¸ë¦¬ê°€ ì•ˆëŒì•„ê°„ë‹¤ ğŸ¤•ğŸ¤•

ê¸°ì¡´ì˜ FCN ê¸°ë°˜ì˜ encoder-decoderêµ¬ì¡°ê°€ ì•„ë‹Œ sequence-to-sequce í˜•íƒœë¡œ transformerë¥¼ segmentationì— ì ìš©í•œ ë…¼ë¬¸

**Introduction**

encoder-decoder : encoderëŠ” feature representation ê¸°ë°˜, decoderëŠ” pixel-level classificationì„ í•¨ ê·¸ë¦¬ê³  ì´ëŸ¬í•œ designì´ ì¸ê¸°ê°€ ìˆëŠ”ì´ìœ ëŠ” translation equivariance and localityë•Œë¬¸ì„ í•˜ì§€ë§Œ segmentationì—ì„œ ì¤‘ìš”í•œ long range dependency informationì„ í•™ìŠµí•˜ëŠ” ê²ƒì€ ì—¬ì „íˆ limited receptive fieldsë¡œ ì–´ë ¤ì›Œì§„ë‹¤ëŠ” í•œê³„ê°€ ìˆìŒ 

ê·¸ë˜ì„œ ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ ì ë‹¤ì–‘í•œ ë°©ë²•ë“¤ì´ ì—°êµ¬ë¨   
conv operationì„ ì¡°ì‘í•˜ëŠ” large kernel sizeì™€ atrous conv, image/feature pyramidë“±ê³¼ ê°™ì€ ë°©ë²•ë“¤ì´ ì—°êµ¬ë˜ì—ˆê³  attention module into FCN architectureë„ ìˆìŒ FCN moduleì€ ë°”ê¾¸ì§€ ì•Šì€ì±„ attentionê³¼ ê²°í•©í•˜ëŠ” ë°©ë²•ì„ í•˜ì§€ë§Œ ì´ë˜í•œ encoder-decoder êµ¬ì¡° encoderì—ì„œëŠ” input resolutionì„ ì¤„ì´ê³  decoderì—ì„œëŠ” lower-resolution feature ë¥¼ ê°œì„ í•˜ëŠ” ë°©ë²•ì„ 

ê·¸ë˜ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” encoder-decoderêµ¬ì¡°ê°€ ì•„ë‹Œ pure transformerêµ¬ì¡°ë¥¼ ì ìš©í•œ SETR(SEgmentation TRansformer)ë¥¼ ì œì•ˆí•¨ 

**Method**

FCN encoderëŠ” conv layerê°€ sequentiallyí•˜ê²Œ stackë˜ì–´ ìˆìŒ high layerì—ì„œ tensor ìœ„ì¹˜ëŠ” receptive fieldë¡œ ì •ì˜ ë˜ëŠ” layerë³„ convë¥¼ í†µí•´ ëª¨ë“  lower layer ì˜ tensorë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ë˜ì–´ì§ ì´ëŸ¬í•œ locality ë•Œë¬¸ì— layerì˜ depthì— ë”°ë¼ ì ì  receoptvie fieldë¥¼ ë†’ì„ ê·¸ ê²°ê³¼ big receptive fieldë¥¼ ê°–ëŠ” higher layerì—ì„œ long-range dependencyë¥¼ ëª¨ë¸ë§ í•  ìˆ˜ ìˆì§€ë§Œ  ë” ë§ì€ ì¸µì„ ì¶”ê°€í•  ë•Œ íŠ¹ì • ê¹Šì´ì— ë„ë‹¬í•˜ë©´ ì¥ì ì´ ì‚¬ë¼ì§ ë”°ë¼ì„œ vanilla FCN êµ¬ì¡° ìì²´ê°€ í•œê³„ê°€ ìˆìŒ

ê·¸ë˜ì„œ FCN with attention mechanismì´ ì œì•ˆë˜ì—ˆìŒ í•˜ì§€ë§Œ ì´ëŸ¬í•œ ë°©ë²•ì€ ì—°ì‚°ëŸ‰ ë•Œë¬¸ì— higher layerì—ì„œë§Œ attentionì„ ì ìš©í•  ìˆ˜ ìˆìŒ ì´ëŠ” low-level featureì˜ ì˜ì¡´ì„±ì´ ë¶€ì¡±í•˜ê³  sub-optimalí•¨ ê·¸ë˜ì„œ ì´ëŸ¬í•œ ë‹¨ì ì„ ê·¹ë³µí•˜ê¸° ìœ„í•´ì„œ SETRì„ ì œì•ˆí•¨

[img1](\assets\post\post13\img1.png)  

* Image to Sequence   
  transformer input 1D sequence of feature embedding  [img2](\assets\post\post13\img2.png)    
  flatten the image pixelì€ ì—°ì‚°ëŸ‰ì´ ë†’ìŒ 
  ê·¸ë˜ì„œ transformer input sequence length L as [img3](\assets\post\post13\img3.png)    
  ì´í›„ reshape target feature map x_f  
  HW/256 - long input sequenceë¥¼ ì–»ê¸° ìœ„í•´ img (H x W x 3)ë¥¼ grid path (H/16 x W /16)ë¡œ ë‚˜ëˆ„ê³  flatten   
  mapping each vectorized patchë¥¼ C-dimensinal embedding spaceë¥¼ ì–»ê¸° ìœ„í•´ linear projection [img4](\assets\post\post13\img4.png)    ì´ë¥¼ í™œìš©í•´ì„œ 1D sequence of patch embedding   
  To encode the patch spacial information, every location iì—ì„œ specific embedding p_i ë¥¼ í•™ìŠµí•¨ ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ final sequece input Eë¥¼ í˜•ì„±í•˜ê¸° ìœ„í•´ p_iì™€ e_ië¥¼ ë”í•¨ [img5](\assets\post\post13\img5.png)    ì´ëŸ¬í•œ ë°©ì‹ìœ¼ë¡œ transformerì˜ self-attention íŠ¹ì„±ì—ë„ ë¶ˆêµ¬í•˜ê³  ê³µê°„ ì •ë³´ê°€ ìœ ì§€ë¨ 
* Transformer   
  1D embedding sequence Eë¥¼ í†µí•´ feature representation -> global receptive field ì„ ì‚¬ìš©í•´ ê¸°ì¡´ FCN encoderêµ¬ì¡°ì˜ í•œê³„ë¥¼ ê°œì„ í•¨  
  transformer encoderëŠ” multi-head self-attention(MSA) and Multilayer Perceptron(MLP)ì˜ L_e layerë¡œ êµ¬ì„±ë¨ 


---
layout: post
title:  "Segmenting Transparent Object in the Wild with Transformer ì •ë¦¬"
date:   2021-03-15 20:34:36 +0530
categories: paper  
---



ì¢€ ë” ì—´ì‹¬íˆ ğŸ˜•ğŸ˜•

íƒ€ê²Ÿì„ transparent objectë¡œ ì¡ì•„ì„œ segmentation 

1. Fine-grained segmentation dataset

2. Trans2Seg
   CNN backbone, encoder-decoder, small conv headë¡œ ì´ë£¨ì–´ì ¸ìˆìŒ  
   ![img1](\assets\post\post12\img1.png)  

   * Feature map of CNN backbone (H/16, W/16, C)

   * Encoder
     Flattened feature of (H/16,W/16, C)   
     positional embedding of (H/16,W/16, C) : sequenceì—ì„œ featureì˜ relative or absolute positionì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µ  
     The encoder is composed of stacked encoder layers, each of which consists of a multi-head self-attention module and a feed forward
     network

   * Decoder  
     ![img2](\assets\post\post12\img2.png)  
     learnable class prototype embedding : query (E_cls)  
     encoded feature : key and value (F_e)    
     ![img3](\assets\post\post12\img3.png)  
     output : new query   
     ![img4](\assets\post\post12\img4.png)   
     output : attention map(N, M, H/16, W/16)   
     N number of category, M number of multi-head attention

     upsampling (N, M H/4, W/4)

     fuse ResNet + attention map (N, M+C, H/4, W/4)

     final output (N, H/4, W/4)


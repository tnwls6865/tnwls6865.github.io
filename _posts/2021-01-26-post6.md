---
layout: post
title:  "Everybody Dance Now"
date:   2021-01-26 16:012:36 +0530
categories: paper
---

ë§¥ë¶ ì£¼ë¬¸í•œê²Œ ì™”ëŠ”ë° ë¶ˆëŸ‰ì´ë‹¤ ã…  ğŸ¤¬

![img1](\assets\post\post6\img1.png)  
ì‚¬ëŒì´ ì¶¤ì¶”ëŠ” ë™ì˜ìƒì—ì„œ ìƒˆë¡œìš´ target videoì— transferí•˜ëŠ” ë…¼ë¬¸  
video-to-video tranlation ëŠë‚Œìœ¼ë¡œ ë³´ë©´ ë ê±° ê°™ìŒ  
sourceì—ì„œ ë¶€í„° poseë¥¼ ì¶”ì¶œí•˜ê³  targetì„ ìƒì„±í•˜ê¸° ìœ„í•´ pose-to-appearancce mappingì„ í•™ìŠµí•¨  
ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ëœ ë¹„ë””ì˜¤ ê²°ê³¼ë¥¼ ìœ„í•´ ë‘ê°œì˜ ì—°ì†ëœ í”„ë ˆì„ì„ ì˜ˆì¸¡í•¨  
ê·¸ë¦¬ê³  target videoì— ëŒ€í•´ì„œ realisticì„ ìœ„í•´ face ì™€ full imageë¡œ pipelineì„ ë¶„ë¦¬í•¨  

#### Introduction

ë³¸ ë…¼ë¬¸ì—ì„œ simpleí•˜ì§€ë§Œ íš¨ê³¼ì ì¸ approachë¥¼ ì œì•ˆí•¨ **"Do as I Do" video retargeting**  
ë‘ ê°œì˜ videoê°€ ì£¼ì–´ì§€ë©´ í•˜ë‚˜ëŠ” source í•˜ë‚˜ëŠ” target  
sourceì—ì„œ targetìœ¼ë¡œ motionì„ transferí•˜ëŠ” ë…¼ë¬¸ 

frame-by-frame ë°©ë²•ìœ¼ë¡œ ë‘ ë¹„ë””ì˜¤ ê°„ì˜ motionì„ transferí•˜ê¸° ìœ„í•´ì„œ ë‘ ê°œê°œì¸ì— ëŒ€í•´ ì´ë¯¸ì§€ ê°„ì˜ mappingì„ í•™ìŠµí•´ì•¼í•¨  
ê·¸ë˜ì„œ pix2pix(image-to-image translation)ì™€ ë¹„ìŠ·í•˜ì§€ë§Œ ë³¸ ë…¼ë¬¸ì€ pairí•œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ , pairí•œ ì´ë¯¸ì§€ê°€ ìˆì–´ë„ ë‘ objectê°€ ê° ìœ ë‹ˆí¬í•œ body shapeê³¼ motionì„ ê°–ê³  ìˆì–´ì„œ ë‹¤ë¦„ 

keypointê¸°ë°˜ í¬ì¦ˆëŠ” motion signaturesë¥¼ ìœ ì§€í•˜ê¸° ë•Œë¬¸ì— pose detectorë¥¼ ì‚¬ìš©í•´ì„œ poseë¥¼ ì¶”ì¶œí•¨  
ê·¸ë¦¬ê³  ë‚˜ì„œ pose stick figureì´ë‘ target person ì´ë¯¸ì§€ë“¤ ê°„ì˜ image-to-imageë¥¼ translation modelì„ í•™ìŠµí•¨  
sourceì—ì„œ targetìœ¼ë¡œ motion transferí•˜ê¸° ìœ„í•´ inputì€ sourceì—ì„œ pose stric figuresë¥¼ ì¶”ì¶œí•˜ê³   sourceì—ì„œ ê°™ì€ í¬ì¦ˆì§€ë§Œ target subject ì´ë¯¸ì§€ë¥¼ ìƒì„±í•¨ 

#### Method

![img2](\assets\post\post6\img2.png)  
Input :  source person video, ë‹¤ë¥¸ target person video  
Output: source motionì²˜ëŸ¼ í–‰ë™í•˜ëŠ” targetì˜ ìƒˆë¡œìš´ video

ì œì•ˆí•˜ëŠ” ëª¨ë¸ì€ 3 íŒŒíŠ¸ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŒ  

1. pose detection  
   pre-trained state-of-the-art(openpose)ë¥¼ í™œìš©í•˜ì—¬ pose estimation
2. global pose normalization  
   sourceì™€ target body shapeê³¼ ìœ„ì¹˜ê°€ ë‹¤ë¥¸ ë¶€ë¶„ì„ ë‹¤ë£¸
3. normalized poseì—ì„œ target subjectë¡œ mapping   
   adversarial trainingì„ ì‚¬ìš©í•˜ì—¬ pose figureì—ì„œ target imgì— mappingí•˜ëŠ” ê²ƒì„ í•™ìŠµ 

**Pose Encoding and Normalization**

* Encodoing body pose  
  ![img3](\assets\post\post6\img3.png)  
  pre-trained pose detector P(OpenPose model)ë¥¼ ì‚¬ìš©í•¨ 
  ì´ë¥¼ í™œìš©í•˜ì—¬ color pose stick figureë¥¼ ìƒì„±
* Global pose normalization  
  ë‘ subjectê°„ retargetingì„ í•  ë•Œ soure poseë¥¼ transfer  
  transferì—ì„œ targetì˜ body shapeê³¼ appearanceë¥¼ ì¼ì¹˜ì‹œì¼œì•¼í•¨  
  subjectì˜ poseì— ëŒ€í•´ heightì™€ poseìœ„ì¹˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ë¹„ë””ì˜¤ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ë°œëª©ìœ„ì¹˜ì™€ ê°€ì¥ ë¨¼ ë°œëª© ìœ„ì¹˜ ê°„ì˜  linear mappingì„ í•¨  
  positionì„ êµ¬í•˜ê³  ê° frameë§ˆë‹¤ scaleê³¼ translationì„ ê³„ì‚°í•¨

**Pose to Video Translation**

pix2pix HDëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ”ë° ëª©ì ì— ë§ê²Œ ìˆ˜ì •í•¨  
GëŠ” pose stick figureê°€ ì£¼ì–´ì§€ë©´ ì‚¬ëŒì˜ í•©ì„± ì´ë¯¸ì§€ë¥¼ ìƒì„±í•¨  
ê¸°ì¡´ì˜ signle-frame image-to-image translation ë°©ë²•ë“¤ì€ videoì— ì‚¬ìš©í•˜ë©´ temporal artifactë¥¼ ìƒì„±í•˜ê³  human motionì— ëŒ€í•´ì„œ detailì„ ìƒì„±í•  ìˆ˜ ì—†ìŒ  
ê·¸ë˜ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” temporal coherence ë¶€ë¶„ê³¼ high resoluti[on ì–¼êµ´ì„ ìƒì„±í•˜ëŠ” ë¶€ë¶„ì„ ì¶”ê°€í•˜ì˜€ìŒ  

* Temporal smoothing  
  
  ![img5](\assets\post\post6\img5.png)  
  ê·¼ì ‘í•œ frameë“¤ ê°„ì˜ temporal coherenceë“¤ì„ ê°•í™”í•˜ê¸° ìœ„í•´ì„œ GeneratorëŠ” ë‘ ê°œì˜ ì—°ì†ì ì¸ í”„ë ˆì„ë“¤ì„ ì˜ˆì¸¡í•¨   
  ê·¸ë˜ì„œ DiscriminatorëŠ” imageë¥¼ Fake or realê³¼ êµ¬ë¶„ ê·¸ë¦¬ê³  temporal coheranceë¥¼ êµ¬ë¶„  
  ![img4](\assets\post\post6\img4.png)  
  ë‘ ê°œì˜ frameì— ëŒ€í•´ì„œ lossë¥¼ ì ìš©í•¨  
  
* Face GAN  
  ![img6](\assets\post\post6\img6.png)  
  ì–¼êµ´ë¶€ë¶„ì— detailì„ ìœ„í•´ì„œ ì‚¬ìš©í•˜ëŠ” part  
  nose ì¤‘ì‹¬ì˜ 128x128ë¶€ë¶„ì´ input  
  outputì€ residual r ![img7](\assets\post\post6\img7.png)  
  ë§ˆì§€ë§‰ í•©ì„± ì–¼êµ´ ì˜ì—­ì€  main generatorì˜ face regionì—ë‹¤ê°€ residualì„ ë”í•¨ 
  r + G(x)  
  discriminator D_fëŠ” "real" face pairs(x_F, y_F)ì¸ì§€ "fake" face paris(x_F, r+G(x)_F)ì¸ì§€ ì•Œì•„ëƒ„ (pix2pixì™€ ë¹„ìŠ·í•˜ê²Œ lossë¥¼ ì„¤ì •)  
  ![img8](\assets\post\post6\img8.png)   
  full imageì™€ ìœ ì‚¬í•˜ê²Œ ìµœì¢… ì–¼êµ´ r+G(X)__Fë¥¼ GTì™€ ë¹„êµí•  ë•Œ perceptrual reconstruction lossë¥¼ ë”í•¨ 
  
* Full Objective
  full image GANì€ face GANê³¼ ë¶„ë¦¬ë˜ì–´ optimize ë¨  
  ![img9](\assets\post\post6\img9.png)   
  temporal coherence + feature matching + perceptron reconstruction   
  ![img10](\assets\post\post6\img10.png) ì€ pix2pixHDì—ì„œ discriminator feature-matching lossë¡œ ì†Œê°œë˜ì—ˆìŒ 
  discriminator feature-matching lossëŠ” discriminator ë‚´ë¶€ì—ì„œ activateionì„ ë¹„ìŠ·í•˜ê²Œ ìœ ë„ ìƒˆë¡œìš´ ëª©í‘œë¥¼ ì§€ì •í•˜ê³  GANì˜ ë¶ˆì•ˆì •ì„±ì„ í•´ê²° ì§„ì§œì™€ ê°€ì§œê°€ ê°™ì€ feaatureë¥¼ ê°–ê³  ìˆëŠ” í™•ì¸ discriminatorì˜ ì¤‘ê°„ì¸µì˜ activation funcì„ ì´ìš©  
  preceptual reconstruction lossëŠ” pretrained VGG featureì™€ networkì˜ ë‹¤ë¥¸ layerì˜ featureë¥¼ ë¹„êµí•˜ëŠ” loss  
  ![img10](\assers\post\post6\img11.png)  
  full image GAN weightëŠ” ì–¼ë ¤ì§€ê³  faceë¥¼ optimizerí•¨ ìœ„ì— lossëŠ” face GANì˜ objective func

**Experiments**
---
layout: post
title:  "Learning What Not to Segment: A New Perspective on Few-Shot Segmentation 정리"
date:   2022-04-11 10:32:36 +0530
categories: paper
---

저번주에 날씨가 좋다고 햇는데 지금은 더워서 죽을 지경 😵‍💫😵‍💫



![img1](\assets\post\post23\img1.png)

기존에 다른 방법들이 meta learning을 통해 generalization의 능력을 향상시킬려고 노력함 하지만 이러한 방법들은 seen class에 대해 bias가 존재하고 new class에 대해 recognition의 성능을 떨어트림 특히 base데이터와 유사한 범주에 대한 hard query sample에 대해서는  일반화 성능이 붕괴됨 

본 논문에서는 additional branch를 추가로 두어서 base class를 학습하고 이를 활용함 

그리고 query와 support간의 차이를 활용해서 adjustment factor로 활용함 

* base learner
  추가적 branch로 base classes에 대한 region을 예측 
  $$f_b^q = F_{conv}(\varepsilon(x^q)) \in R^{c\times H\times W}$$
  $$P_b = softmax(D_b(f^q_b)) \in R^{(1+N_b)\times H\times W}$$ : $$D_b$$ - decoder network (enlarge the spatial scale), $$N_b$$ - number of base categories
  episodic learning이 아닌 standard supervised learning 
  $$L_{base} = {1\over n_{bs}} \sum_{i=1}^{n_{bs}}CE(p_{b;i}, m^q_{b;i})$$ : $$P_b$$ - prediction , $$m_b^q$$: ground truth 
  **기존 모델을 그대로 쓰면 너무 깊고 infernece 속도 오래 걸리기때문에 meta branch에서 같은 backbone을 얼리는 걸 시도해봣지만 standard segmentation성능이 떨어짐 그래서 two training strategy를 활용 **

* meta learner

  support set : $$S = x^s, m^s$$ query image: $$x^q$$ 

  annotation mask에서 같은 카테고리인거에 대해 segment하는 것이 목표
  $$f^s_m = F_{1\times1}(\varepsilon(x^s)) \in R^{c\times h\times w}$$
  $$f^q_m = F_{1\times1}(\varepsilon(x^q)) \in R^{c\times h\times w}$$
  crucial class-related cues를 제공하기 위해서 masked average pooling(MAP)를 활용 $$(f^s_m, m_s)$$ 
  $$v_s = F_{pool}(f_m^s \odot I(m^s)) \in R^c$$ : $$I$$ - reshape function $$R^{H\times W} -> R^{c\times h\times w}$$
  $$p_m = softmax(D_m(F_{guidance(v_s, f_m^q)})) \in R^{2\times H\times W}$$ : $$F_{guidance}$$-supprot branch에서 query branch로 segmentation cues를 제공하는 annotation information 역할 expand & concatenate operation 
  $$L_meta = {1\over n_e} \sum_{i=1}^{n_e}BCE(p_{m;i}, m^q_i)$$ : $$n_e$$ - number of training episodes

* ensemble module 
  ![img2](\assets\post\post23\img2.png)
  meta learner는 support set의 영향을 받기 때문에 query-support이미지 간의 차이에 대한 평가 결과를 활용하여  coarse prediction에 대해서 조정하는 모듈을 제안 
  background region에 관련된 영역을 얻기 위해 base learner에서 foreground probability를 통합함
  $$ p^f_b = \sum_{i=1}^{N_b} p_b^i$$
  fixed backbone 으로 부터 추출한 low-level feature $$f^s_{low}, f_{low}^q \in R^{C_1\times H_1\times W_1}$$  에 대해 gram matrices를 추출
  $$A_s = F_{reshape}(f^s_{low}) \in R^{C_1 \times N}$$
  $$ G^s = A_s A_s^\top \in R^{C_1\times C_1}$$
  frobenius norm을 통해 adjustment process를 가이드하기 위한 전체적인 indicator $$\psi$$ 를 얻음
  $$ \psi = ||G^s - G^q||_F$$
  coarse results에 $$\psi$$를 통합함
  $$p_0^f =F_{ensemble}(F_\psi(p_m^0), p_b^t)$$
  $$p_f = p_f^0 \oplus F_{\psi}(p_m^1)$$
  $$F_\psi, F_{ensemble} $$:  1x1 conv,  $$\oplus$$ : concat
  $$L_{final} = {1 \over n_e} \sum_{i=1}^{n_e}BCE(p_i^q, m_i^q)$$

  $$L = L_{final} + \lambda L_{meta} $$